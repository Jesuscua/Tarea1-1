# Tarea1

## life cycle of data analysis

### Business Understanding:
#### This initial phase focuses on understanding the objectives and requirements of the project from a business perspective, and then converting this knowledge into a definition of data mining problem. A preliminary plan is designed to achieve the objectives. A decision model can be used, especially one created using the decision model and the notation standard.

### Understanding the data:
#### The data comprehension phase begins with an initial collection of data and continues with activities to familiarize yourself with the data, identify data quality problems, discover the first ideas about the data or detect interesting subsets to form hypotheses to hide information. 

### Data Preparation:
####  The data preparation phase covers all activities to build the final data set (data that will be incorporated into the modeling tools) from the initial raw data. Data preparation tasks are likely to be performed several times and not in the prescribed order. Tasks include the selection of tables, records and attributes, as well as the transformation and cleaning of data for modeling tools.

### Modeling:
#### In this phase, several modeling techniques are selected and applied and their parameters are calibrated to optimal values. Generally, there are several techniques for the same type of data mining problem. Some techniques have specific requirements on the form of the data. Therefore, it is often required to go back to the data preparation phase.

### Evaluation:
#### At this stage of the project, you have created a model (or models) that seems to have high quality, from the perspective of data analysis. Before proceeding with the final deployment of the model, it is important to evaluate it thoroughly and review the steps taken to build the model, to ensure that it adequately achieves business objectives. A key objective is to determine if there is an important commercial problem that has not been sufficiently considered. At the end of this phase, a decision must be reached on the use of data mining results.

### Implementation:
#### Model creation is generally not the end of the project. Even if the purpose of the model is to increase the knowledge of the data, the knowledge acquired should be organized and presented in a way that is useful to the customer. Depending on the requirements, the implementation phase can be as simple as generating a report or as complex as implementing a repeatable data score (for example, segment assignment) or a data mining process.

## Types of statistics

### Inferential statistics:
#### Inferential statistics are produced through complex mathematical calculations that allow scientists to infer trends over a larger population based on the study of a sample taken from it. Scientists use inferential statistics to examine the relationships between variables within a sample and then make generalizations or predictions about how those variables will relate to a larger population.

### Descriptive statistics:
#### Descriptive statistics is the type of statistics that probably arises in the minds of most people when they hear the word "statistics." In this branch of statistics, the objective is to describe. Numerical measurements are used to report the characteristics of a data set. There are a number of elements that belong to this part of the statistics.

### APPLIED:
####  It is made up of the two kinds of previous statistics. Its objective is to deduce results on a universe, from a given sample. This type of statistics can be applied in any area that does not belong to it, such as history, psychology, etc.

### MATHEMATICAL STATISTICS:
#### It refers to the use of statistics but from a formal point of view, through the use of different branches of mathematics and probability theory. Its use is necessary because the data handled by mathematical statistics are random and uncertain.

## EDA
#### Exploratory Data Analysis (EDA) is an approach / philosophy for data analysis that employs a variety of (mainly graphic) techniques to:
1. Maximize knowledge of a data set;
2. discover the underlying structure;
3. extract important variables;
4. detect outliers and anomalies;
5. prove underlying assumptions;
6. develop parsimonious models; Y
7. determine the optimal factor setting.

